use crate::commands::audit;
use crate::commands::audit::relative_path;
use crate::core::receipt::Receipt;
use crate::core::{model_classifier, redact, session_stats};
use chrono::Utc;
use std::cmp::Reverse;
use std::collections::{HashMap, HashSet};
use std::fmt::Write;

struct SecurityFinding {
    session_id: String,
    date: String,
    user: String,
    secret_type: String,
    severity: String,
}

pub fn generate_report(
    output_path: &str,
    from: Option<&str>,
    to: Option<&str>,
    author: Option<&str>,
    include_uncommitted: bool,
) -> Result<(), String> {
    let mut entries = audit::collect_all_entries(from, to, author, include_uncommitted)?;

    // Auto-include staging data if no committed entries found
    if entries.is_empty() && !include_uncommitted {
        let staged = audit::collect_staged_entries();
        if !staged.is_empty() {
            entries = staged;
        }
    }

    // Collect all receipts
    let all_receipts: Vec<&Receipt> = entries.iter().flat_map(|e| &e.receipts).collect();

    // Classify models
    let classifications: Vec<_> = all_receipts
        .iter()
        .map(|r| (r.model.clone(), model_classifier::classify(&r.model)))
        .collect();

    // Security scan
    let security_findings = scan_prompts_for_secrets(&all_receipts);

    // Get repo name
    let repo_name = std::env::current_dir()
        .ok()
        .and_then(|p| p.file_name().map(|n| n.to_string_lossy().to_string()))
        .unwrap_or_else(|| "unknown".to_string());

    let total_commits = count_total_commits();

    let mut md = String::new();

    // Section 1: Executive Summary
    write_executive_summary(
        &mut md,
        &repo_name,
        &entries,
        &all_receipts,
        total_commits,
        from,
        to,
    );

    // Section 2: AI vs Human Code Attribution
    write_ai_vs_human(&mut md, &all_receipts);

    // Section 3: Token & Cost Analysis
    write_cost_analysis(&mut md, &all_receipts, &entries);

    // Section 4: User Contribution Matrix
    write_user_contributions(&mut md, &all_receipts);

    // Section 5: Time & Generation Speed Analysis
    write_time_analysis(&mut md, &all_receipts);

    // Section 6: Security Audit
    write_security_audit(&mut md, &security_findings, &all_receipts);

    // Section 7: Model Usage Comparison
    write_model_comparison(&mut md, &all_receipts, &classifications);

    // Section 8: File-Level Heatmap
    write_file_heatmap(&mut md, &all_receipts);

    // Section 9: Session Deep Dive
    write_session_analysis(&mut md, &all_receipts);

    // Section 10: Prompt Details
    write_prompt_details(&mut md, &entries);

    // Section 11: Recommendations
    write_recommendations(&mut md, &all_receipts, &classifications, &security_findings);

    // Footer
    writeln!(md, "\n---").ok();
    writeln!(
        md,
        "*Generated by [BlamePrompt](https://github.com/ekaanth/blameprompt) v{}*",
        env!("CARGO_PKG_VERSION")
    )
    .ok();

    std::fs::write(output_path, &md).map_err(|e| format!("Cannot write report: {}", e))?;

    println!("Report written to {}", output_path);
    Ok(())
}

fn count_total_commits() -> u32 {
    std::process::Command::new("git")
        .args(["rev-list", "--count", "HEAD"])
        .output()
        .ok()
        .and_then(|o| String::from_utf8(o.stdout).ok())
        .and_then(|s| s.trim().parse().ok())
        .unwrap_or(0)
}

fn write_executive_summary(
    md: &mut String,
    repo_name: &str,
    entries: &[audit::AuditEntry],
    receipts: &[&Receipt],
    total_commits: u32,
    from: Option<&str>,
    to: Option<&str>,
) {
    let today = Utc::now().format("%Y-%m-%d");
    let period = match (from, to) {
        (Some(f), Some(t)) => format!("{} to {}", f, t),
        _ => "entire history".to_string(),
    };

    let commits_with_ai = entries.len() as u32;
    let pct = if total_commits > 0 {
        (commits_with_ai as f64 / total_commits as f64) * 100.0
    } else {
        0.0
    };

    let session_ids: HashSet<&str> = receipts.iter().map(|r| r.session_id.as_str()).collect();
    let unique_files: HashSet<String> = receipts.iter().flat_map(|r| r.all_file_paths()).collect();
    let unique_users: HashSet<&str> = receipts.iter().map(|r| r.user.as_str()).collect();
    let total_lines: u32 = receipts.iter().map(|r| r.total_lines_changed()).sum();
    let total_cost: f64 = receipts.iter().map(|r| r.cost_usd).sum();

    let providers: HashSet<&str> = receipts.iter().map(|r| r.provider.as_str()).collect();
    let tools: Vec<&str> = providers.into_iter().collect();

    writeln!(md, "# BlamePrompt Report: {}", repo_name).ok();
    writeln!(
        md,
        "> Generated: {} | Period: {} | Commits: {}\n",
        today, period, total_commits
    )
    .ok();
    writeln!(md, "## Executive Summary\n").ok();
    writeln!(md, "| Metric | Value |").ok();
    writeln!(md, "|--------|-------|").ok();
    writeln!(md, "| Total commits analyzed | {} |", total_commits).ok();
    writeln!(
        md,
        "| Commits with AI-generated code | {} ({:.1}%) |",
        commits_with_ai, pct
    )
    .ok();
    writeln!(md, "| Total AI-assisted sessions | {} |", session_ids.len()).ok();
    writeln!(
        md,
        "| Total files modified by AI | {} |",
        unique_files.len()
    )
    .ok();
    writeln!(md, "| Total AI-generated lines | {} |", total_lines).ok();
    writeln!(md, "| Estimated total AI cost | ${:.2} |", total_cost).ok();
    writeln!(md, "| Unique contributors | {} |", unique_users.len()).ok();
    writeln!(md, "| AI tools used | {} |", tools.join(", ")).ok();

    // Aggregate tools, MCPs, agents across all receipts
    let mut all_tools: HashSet<&str> = HashSet::new();
    let mut all_mcps: HashSet<&str> = HashSet::new();
    let mut all_agents: Vec<&str> = Vec::new();
    for r in receipts {
        for t in &r.tools_used {
            all_tools.insert(t.as_str());
        }
        for m in &r.mcp_servers {
            all_mcps.insert(m.as_str());
        }
        for a in &r.agents_spawned {
            if !all_agents.contains(&a.as_str()) {
                all_agents.push(a.as_str());
            }
        }
    }
    if !all_tools.is_empty() {
        let mut tools_list: Vec<&str> = all_tools.into_iter().collect();
        tools_list.sort();
        writeln!(md, "| Tools used | {} |", tools_list.join(", ")).ok();
    }
    if !all_mcps.is_empty() {
        let mut mcps_list: Vec<&str> = all_mcps.into_iter().collect();
        mcps_list.sort();
        writeln!(md, "| MCP servers | {} |", mcps_list.join(", ")).ok();
    }
    if !all_agents.is_empty() {
        writeln!(md, "| Sub-agents spawned | {} |", all_agents.len()).ok();
    }

    let uncommitted_count = entries
        .iter()
        .filter(|e| e.commit_sha == "uncommitted")
        .map(|e| e.receipts.len())
        .sum::<usize>();
    if uncommitted_count > 0 {
        writeln!(md, "| Uncommitted AI receipts | {} |", uncommitted_count).ok();
    }

    writeln!(md).ok();
}

fn write_ai_vs_human(md: &mut String, receipts: &[&Receipt]) {
    writeln!(md, "## AI vs Human Code Attribution\n").ok();

    let total_ai_lines: u32 = receipts.iter().map(|r| r.total_lines_changed()).sum();

    writeln!(md, "### Overall").ok();
    writeln!(md, "- **AI-generated**: {} lines", total_ai_lines).ok();
    writeln!(md).ok();

    // By directory
    let mut by_dir: HashMap<String, u32> = HashMap::new();
    for r in receipts {
        for fc in r.all_file_changes() {
            let rel = relative_path(&fc.path);
            let dir = std::path::Path::new(&rel)
                .parent()
                .map(|p| p.to_string_lossy().to_string())
                .unwrap_or_else(|| ".".to_string());
            let lines = if fc.line_range.1 >= fc.line_range.0 {
                fc.line_range.1 - fc.line_range.0 + 1
            } else {
                0
            };
            *by_dir.entry(dir).or_insert(0) += lines;
        }
    }

    if !by_dir.is_empty() {
        writeln!(md, "### By Directory").ok();
        writeln!(md, "| Directory | AI Lines |").ok();
        writeln!(md, "|-----------|----------|").ok();
        let mut dirs: Vec<_> = by_dir.into_iter().collect();
        dirs.sort_by_key(|b| Reverse(b.1));
        for (dir, lines) in &dirs {
            writeln!(md, "| {} | {} |", dir, lines).ok();
        }
        writeln!(md).ok();
    }

    // Top AI-heavy files
    let mut by_file: HashMap<String, (u32, String)> = HashMap::new();
    for r in receipts {
        for fc in r.all_file_changes() {
            let lines = if fc.line_range.1 >= fc.line_range.0 {
                fc.line_range.1 - fc.line_range.0 + 1
            } else {
                0
            };
            let entry = by_file
                .entry(relative_path(&fc.path))
                .or_insert((0, r.model.clone()));
            entry.0 += lines;
        }
    }

    if !by_file.is_empty() {
        writeln!(md, "### Top AI-Heavy Files").ok();
        writeln!(md, "| File | AI Lines | Model Used |").ok();
        writeln!(md, "|------|----------|------------|").ok();
        let mut files: Vec<_> = by_file.into_iter().collect();
        files.sort_by_key(|b| Reverse(b.1 .0));
        for (file, (lines, model)) in files.iter().take(10) {
            let display = model_classifier::display_name(model);
            writeln!(md, "| {} | {} | {} |", file, lines, display).ok();
        }
        writeln!(md).ok();
    }
}

fn write_cost_analysis(md: &mut String, receipts: &[&Receipt], entries: &[audit::AuditEntry]) {
    writeln!(md, "## Token & Cost Analysis\n").ok();

    let total_cost: f64 = receipts.iter().map(|r| r.cost_usd).sum();
    let session_ids: HashSet<&str> = receipts.iter().map(|r| r.session_id.as_str()).collect();
    let session_count = session_ids.len();

    writeln!(md, "### Cost Summary").ok();
    writeln!(md, "| Metric | Value |").ok();
    writeln!(md, "|--------|-------|").ok();
    writeln!(md, "| Total estimated cost | ${:.2} |", total_cost).ok();
    if session_count > 0 {
        writeln!(
            md,
            "| Avg cost per session | ${:.3} |",
            total_cost / session_count as f64
        )
        .ok();
    }
    if !entries.is_empty() {
        writeln!(
            md,
            "| Avg cost per AI commit | ${:.3} |",
            total_cost / entries.len() as f64
        )
        .ok();
    }
    writeln!(md).ok();

    // Cost by model
    let mut by_model: HashMap<String, (u32, f64)> = HashMap::new();
    for r in receipts {
        let entry = by_model.entry(r.model.clone()).or_insert((0, 0.0));
        entry.0 += 1;
        entry.1 += r.cost_usd;
    }

    writeln!(md, "### Cost by Model").ok();
    writeln!(md, "| Model | Receipts | Est. Cost | % of Total |").ok();
    writeln!(md, "|-------|----------|-----------|------------|").ok();
    let mut models: Vec<_> = by_model.into_iter().collect();
    models.sort_by(|a, b| {
        b.1 .1
            .partial_cmp(&a.1 .1)
            .unwrap_or(std::cmp::Ordering::Equal)
    });
    for (model, (count, cost)) in &models {
        let display = model_classifier::display_name(model);
        let pct = if total_cost > 0.0 {
            cost / total_cost * 100.0
        } else {
            0.0
        };
        writeln!(
            md,
            "| {} | {} | ${:.2} | {:.1}% |",
            display, count, cost, pct
        )
        .ok();
    }
    writeln!(md).ok();
}

fn write_user_contributions(md: &mut String, receipts: &[&Receipt]) {
    writeln!(md, "## User Contributions\n").ok();

    let mut by_user: HashMap<String, (u32, u32, f64)> = HashMap::new();
    for r in receipts {
        let lines = r.total_lines_changed();
        let entry = by_user.entry(r.user.clone()).or_insert((0, 0, 0.0));
        entry.0 += 1; // sessions
        entry.1 += lines;
        entry.2 += r.cost_usd;
    }

    writeln!(md, "| User | AI Sessions | AI Lines | Est. Cost |").ok();
    writeln!(md, "|------|-------------|----------|-----------|").ok();
    let mut users: Vec<_> = by_user.into_iter().collect();
    users.sort_by(|a, b| {
        b.1 .2
            .partial_cmp(&a.1 .2)
            .unwrap_or(std::cmp::Ordering::Equal)
    });
    for (user, (sessions, lines, cost)) in &users {
        writeln!(md, "| {} | {} | {} | ${:.2} |", user, sessions, lines, cost).ok();
    }
    writeln!(md).ok();
}

fn write_time_analysis(md: &mut String, receipts: &[&Receipt]) {
    writeln!(md, "## Time & AI Generation Analysis\n").ok();

    let stats = session_stats::calculate(receipts);

    let total_ai_lines: u32 = receipts.iter().map(|r| r.total_lines_changed()).sum();

    let estimated_saved_hours = session_stats::estimate_dev_hours_saved(total_ai_lines);

    // Use wall-clock time (merged intervals) when available.
    // Fallback priority: per-prompt durations sum > raw session sum.
    // Never use the raw session sum alone â€” it double-counts parallel sub-agent sessions.
    let total_prompt_duration_secs: u64 = receipts
        .iter()
        .filter_map(|r| r.prompt_duration_secs)
        .sum();
    let effective_duration = if stats.wall_clock_secs > 0 {
        stats.wall_clock_secs
    } else if total_prompt_duration_secs > 0 {
        total_prompt_duration_secs
    } else {
        // Last resort: use max single-session duration rather than the full sum
        // to avoid doubling sub-agent time when timestamps are unavailable.
        stats.per_session.values().copied().max().unwrap_or(0)
    };

    writeln!(md, "### Total Time Invested in AI").ok();
    writeln!(md, "| Metric | Value |").ok();
    writeln!(md, "|--------|-------|").ok();
    if let Some(start) = stats.earliest_start {
        writeln!(
            md,
            "| First session start | {} |",
            start.format("%Y-%m-%d %H:%M:%S UTC")
        )
        .ok();
    }
    if let Some(end) = stats.latest_end {
        writeln!(
            md,
            "| Last session end | {} |",
            end.format("%Y-%m-%d %H:%M:%S UTC")
        )
        .ok();
    }
    writeln!(
        md,
        "| Wall-clock time (merged) | {} |",
        session_stats::format_duration(effective_duration)
    )
    .ok();
    if stats.wall_clock_secs > 0 && stats.total_duration_secs > stats.wall_clock_secs {
        writeln!(
            md,
            "| Raw session time (before merge) | {} |",
            session_stats::format_duration(stats.total_duration_secs)
        )
        .ok();
        let saved = stats.total_duration_secs - stats.wall_clock_secs;
        writeln!(
            md,
            "| Parallel agent overlap | {} (sub-agents ran concurrently) |",
            session_stats::format_duration(saved)
        )
        .ok();
    }
    writeln!(md, "| Unique sessions | {} |", stats.unique_sessions).ok();
    if stats.unique_sessions > 0 {
        writeln!(
            md,
            "| Avg session duration | {} |",
            session_stats::format_duration(stats.avg_duration_secs)
        )
        .ok();
    }
    writeln!(md, "| Total AI-generated lines | {} |", total_ai_lines).ok();
    writeln!(
        md,
        "| Estimated dev-hours saved | ~{:.1}h ({} AI lines x 30s/line) |",
        estimated_saved_hours, total_ai_lines
    )
    .ok();
    if effective_duration > 0 && estimated_saved_hours > 0.0 {
        let roi = estimated_saved_hours / (effective_duration as f64 / 3600.0);
        writeln!(md, "| Time ROI | {:.1}x |", roi).ok();
    }
    writeln!(md).ok();

    // Response speed by model
    let mut model_response_times: HashMap<String, Vec<f64>> = HashMap::new();
    for r in receipts {
        if let Some(rt) = r.ai_response_time_secs {
            model_response_times
                .entry(r.model.clone())
                .or_default()
                .push(rt);
        }
    }

    if !model_response_times.is_empty() {
        writeln!(md, "### AI Model Response Speed").ok();
        writeln!(md, "| Model | Avg Response | Sessions |").ok();
        writeln!(md, "|-------|-------------|----------|").ok();
        for (model, times) in &model_response_times {
            let avg = times.iter().sum::<f64>() / times.len() as f64;
            let display = model_classifier::display_name(model);
            writeln!(md, "| {} | {:.1}s | {} |", display, avg, times.len()).ok();
        }
        writeln!(md).ok();
    }
}

fn write_security_audit(md: &mut String, findings: &[SecurityFinding], receipts: &[&Receipt]) {
    writeln!(md, "## Security Audit\n").ok();

    let total_prompts = receipts.len();
    let prompts_with_secrets = findings.len();

    writeln!(md, "### Redaction Summary").ok();
    writeln!(md, "- **Total prompts scanned**: {}", total_prompts).ok();
    writeln!(
        md,
        "- **Prompts with secrets detected**: {} ({:.1}%)",
        prompts_with_secrets,
        if total_prompts > 0 {
            prompts_with_secrets as f64 / total_prompts as f64 * 100.0
        } else {
            0.0
        }
    )
    .ok();
    writeln!(md, "- **All secrets were auto-redacted**: Yes").ok();
    writeln!(md).ok();

    if !findings.is_empty() {
        writeln!(md, "### Flagged Sessions").ok();
        writeln!(md, "| Session | Date | User | Secret Type | Severity |").ok();
        writeln!(md, "|---------|------|------|-------------|----------|").ok();
        for f in findings {
            writeln!(
                md,
                "| {} | {} | {} | {} | {} |",
                &f.session_id, f.date, f.user, f.secret_type, f.severity
            )
            .ok();
        }
        writeln!(md).ok();
    }
}

fn write_model_comparison(
    md: &mut String,
    receipts: &[&Receipt],
    classifications: &[(String, model_classifier::ModelClassification)],
) {
    writeln!(md, "## Model Usage: Open-Source vs Closed-Source\n").ok();

    let mut open_sessions = 0u32;
    let mut closed_sessions = 0u32;
    let mut open_cost = 0.0f64;
    let mut closed_cost = 0.0f64;
    let mut local_sessions = 0u32;
    let mut cloud_sessions = 0u32;

    for (i, r) in receipts.iter().enumerate() {
        let c = &classifications[i].1;
        match c.license {
            model_classifier::ModelLicense::OpenSource => {
                open_sessions += 1;
                open_cost += r.cost_usd;
            }
            model_classifier::ModelLicense::ClosedSource => {
                closed_sessions += 1;
                closed_cost += r.cost_usd;
            }
        }
        match c.deployment {
            model_classifier::ModelDeployment::Local => local_sessions += 1,
            model_classifier::ModelDeployment::Cloud => cloud_sessions += 1,
        }
    }

    writeln!(md, "### License Breakdown").ok();
    writeln!(md, "| License | Sessions | Est. Cost |").ok();
    writeln!(md, "|---------|----------|-----------|").ok();
    writeln!(
        md,
        "| Closed-source | {} | ${:.2} |",
        closed_sessions, closed_cost
    )
    .ok();
    writeln!(
        md,
        "| Open-source | {} | ${:.2} |",
        open_sessions, open_cost
    )
    .ok();
    writeln!(md).ok();

    writeln!(md, "### Deployment Breakdown").ok();
    writeln!(md, "| Deployment | Sessions |").ok();
    writeln!(md, "|-----------|----------|").ok();
    writeln!(md, "| Cloud | {} |", cloud_sessions).ok();
    writeln!(md, "| Local | {} |", local_sessions).ok();
    writeln!(md).ok();

    let mut by_vendor: HashMap<String, (String, u32, f64)> = HashMap::new();
    for (i, r) in receipts.iter().enumerate() {
        let c = &classifications[i].1;
        let license_str = match c.license {
            model_classifier::ModelLicense::OpenSource => "Open",
            model_classifier::ModelLicense::ClosedSource => "Closed",
        };
        let entry = by_vendor
            .entry(c.vendor.clone())
            .or_insert((license_str.to_string(), 0, 0.0));
        entry.1 += 1;
        entry.2 += r.cost_usd;
    }

    writeln!(md, "### Vendor Comparison").ok();
    writeln!(md, "| Vendor | License | Sessions | Est. Cost |").ok();
    writeln!(md, "|--------|---------|----------|-----------|").ok();
    let mut vendors: Vec<_> = by_vendor.into_iter().collect();
    vendors.sort_by(|a, b| {
        b.1 .2
            .partial_cmp(&a.1 .2)
            .unwrap_or(std::cmp::Ordering::Equal)
    });
    for (vendor, (license, sessions, cost)) in &vendors {
        writeln!(
            md,
            "| {} | {} | {} | ${:.2} |",
            vendor, license, sessions, cost
        )
        .ok();
    }
    writeln!(md).ok();
}

fn write_file_heatmap(md: &mut String, receipts: &[&Receipt]) {
    writeln!(md, "## File-Level AI Heatmap\n").ok();

    let mut by_file: HashMap<String, (u32, u32, String, String)> = HashMap::new();
    for r in receipts {
        for fc in r.all_file_changes() {
            let lines = if fc.line_range.1 >= fc.line_range.0 {
                fc.line_range.1 - fc.line_range.0 + 1
            } else {
                0
            };
            let entry = by_file.entry(relative_path(&fc.path)).or_insert((
                0,
                0,
                String::new(),
                String::new(),
            ));
            entry.0 += 1; // edits
            entry.1 += lines;
            entry.2 = r.timestamp.format("%Y-%m-%d").to_string(); // last edit
            entry.3 = r.model.clone();
        }
    }

    writeln!(md, "### Most AI-Modified Files").ok();
    writeln!(
        md,
        "| Rank | File | AI Edits | AI Lines | Last AI Edit | Primary Model |"
    )
    .ok();
    writeln!(
        md,
        "|------|------|----------|----------|-------------|---------------|"
    )
    .ok();
    let mut files: Vec<_> = by_file.into_iter().collect();
    files.sort_by_key(|b| Reverse(b.1 .1));
    for (rank, (file, (edits, lines, last_edit, model))) in files.iter().enumerate().take(20) {
        let display = model_classifier::display_name(model);
        writeln!(
            md,
            "| {} | {} | {} | {} | {} | {} |",
            rank + 1,
            file,
            edits,
            lines,
            last_edit,
            display
        )
        .ok();
    }
    writeln!(md).ok();
}

fn write_session_analysis(md: &mut String, receipts: &[&Receipt]) {
    writeln!(md, "## Session Analysis\n").ok();

    let session_ids: HashSet<&str> = receipts.iter().map(|r| r.session_id.as_str()).collect();

    let mut session_stats: HashMap<String, (u32, HashSet<String>, f64, String)> = HashMap::new();
    for r in receipts {
        let entry = session_stats.entry(r.session_id.clone()).or_insert((
            0,
            HashSet::new(),
            0.0,
            String::new(),
        ));
        entry.0 = entry.0.max(r.message_count);
        for f in r.all_file_paths() {
            entry.1.insert(relative_path(&f));
        }
        entry.2 += r.cost_usd;
        if entry.3.is_empty() {
            entry.3 = r.prompt_summary.chars().take(50).collect();
        }
    }

    writeln!(md, "### Session Statistics").ok();
    writeln!(md, "| Metric | Value |").ok();
    writeln!(md, "|--------|-------|").ok();
    writeln!(md, "| Total unique sessions | {} |", session_ids.len()).ok();
    let single_file = session_stats.values().filter(|s| s.1.len() == 1).count();
    let multi_file = session_stats.values().filter(|s| s.1.len() > 1).count();
    writeln!(md, "| Sessions modifying 1 file | {} |", single_file).ok();
    writeln!(md, "| Sessions modifying 2+ files | {} |", multi_file).ok();
    writeln!(md).ok();

    // Top sessions
    let mut sessions: Vec<_> = session_stats.into_iter().collect();
    sessions.sort_by_key(|b| Reverse(b.1 .0));

    writeln!(md, "### Top Sessions by Message Count").ok();
    writeln!(
        md,
        "| Session ID | Messages | Files | Est. Cost | Prompt Summary |"
    )
    .ok();
    writeln!(
        md,
        "|-----------|----------|-------|-----------|---------------|"
    )
    .ok();
    for (sid, (msgs, files, cost, prompt)) in sessions.iter().take(10) {
        let short_sid: String = sid.chars().take(8).collect();
        writeln!(
            md,
            "| {} | {} | {} | ${:.2} | \"{}\" |",
            short_sid,
            msgs,
            files.len(),
            cost,
            prompt
        )
        .ok();
    }
    writeln!(md).ok();
}

fn write_prompt_details(md: &mut String, entries: &[audit::AuditEntry]) {
    writeln!(md, "## Prompt Details\n").ok();
    writeln!(md, "Full prompt context for each AI-assisted change.\n").ok();

    // Track which sessions have already shown their duration
    let mut sessions_shown: HashSet<String> = HashSet::new();

    for entry in entries {
        if entry.receipts.is_empty() {
            continue;
        }

        let sha_display = if entry.commit_sha == "uncommitted" {
            "Uncommitted (Staging)".to_string()
        } else {
            format!(
                "Commit `{}`",
                &entry.commit_sha[..std::cmp::min(8, entry.commit_sha.len())]
            )
        };

        writeln!(md, "### {}\n", sha_display).ok();
        writeln!(md, "- **Date**: {}", entry.commit_date).ok();
        writeln!(md, "- **Author**: {}", entry.commit_author).ok();
        if entry.commit_sha != "uncommitted" {
            writeln!(md, "- **Message**: {}", entry.commit_message).ok();
        }
        writeln!(md).ok();

        for r in &entry.receipts {
            let file_changes = r.all_file_changes();
            let files_display: Vec<String> = file_changes
                .iter()
                .map(|fc| relative_path(&fc.path))
                .collect();
            writeln!(
                md,
                "#### {} | `{}` via {}\n",
                files_display.join(", "),
                r.model,
                r.provider
            )
            .ok();
            writeln!(md, "| Field | Value |").ok();
            writeln!(md, "|-------|-------|").ok();
            writeln!(md, "| Session ID | `{}` |", r.session_id).ok();
            writeln!(md, "| Messages | {} |", r.message_count).ok();
            writeln!(md, "| Cost | ${:.4} |", r.cost_usd).ok();
            writeln!(md, "| Files | {} |", file_changes.len()).ok();
            writeln!(md, "| Total lines | {} |", r.total_lines_changed()).ok();
            writeln!(md, "| Prompt Hash | `{}` |", r.prompt_hash).ok();
            if !r.tools_used.is_empty() {
                writeln!(md, "| Tools | {} |", r.tools_used.join(", ")).ok();
            }
            if !r.mcp_servers.is_empty() {
                writeln!(md, "| MCP Servers | {} |", r.mcp_servers.join(", ")).ok();
            }
            if !r.agents_spawned.is_empty() {
                writeln!(md, "| Agents Spawned | {} |", r.agents_spawned.join("; ")).ok();
            }
            writeln!(md).ok();
            for fc in &file_changes {
                writeln!(
                    md,
                    "- `{}` (lines {}-{})",
                    relative_path(&fc.path),
                    fc.line_range.0,
                    fc.line_range.1
                )
                .ok();
            }
            writeln!(md).ok();

            // Show the actual prompt summary
            writeln!(md, "**Prompt:**").ok();
            writeln!(md, "> {}\n", r.prompt_summary).ok();

            // Show per-prompt duration (precise) when available, else session duration
            if let Some(duration) = r.prompt_duration_secs {
                writeln!(
                    md,
                    "- Prompt duration: {}",
                    session_stats::format_duration(duration)
                )
                .ok();
            }
            // Only show session timing on first receipt per session
            if sessions_shown.insert(r.session_id.clone()) {
                if let Some(start) = r.session_start {
                    writeln!(
                        md,
                        "- Session start: {}",
                        start.format("%Y-%m-%d %H:%M:%S UTC")
                    )
                    .ok();
                }
                if let Some(duration) = r.session_duration_secs {
                    writeln!(
                        md,
                        "- Total session duration: {}",
                        session_stats::format_duration(duration)
                    )
                    .ok();
                }
            }
            if let Some(response_time) = r.ai_response_time_secs {
                writeln!(md, "- Avg AI response: {:.1}s", response_time).ok();
            }
            writeln!(md).ok();
        }

        writeln!(md, "---\n").ok();
    }
}

fn write_recommendations(
    md: &mut String,
    receipts: &[&Receipt],
    classifications: &[(String, model_classifier::ModelClassification)],
    findings: &[SecurityFinding],
) {
    writeln!(md, "## Recommendations\n").ok();
    writeln!(md, "Based on the analysis:\n").ok();

    let mut rec_num = 1;

    // Check Opus usage
    let opus_count = receipts
        .iter()
        .filter(|r| r.model.to_lowercase().contains("opus"))
        .count();
    let total = receipts.len();
    if total > 0 && (opus_count as f64 / total as f64) > 0.3 {
        writeln!(
            md,
            "{}. **Cost Optimization**: {:.0}% of sessions used Opus models (higher cost).",
            rec_num,
            opus_count as f64 / total as f64 * 100.0
        )
        .ok();
        writeln!(
            md,
            "   Consider using Sonnet for simpler tasks to reduce costs.\n"
        )
        .ok();
        rec_num += 1;
    }

    // Security
    if !findings.is_empty() {
        writeln!(
            md,
            "{}. **Security**: {} session(s) contained secrets in prompts.",
            rec_num,
            findings.len()
        )
        .ok();
        writeln!(md, "   Consider adding pre-commit checks to warn developers before sending secrets to AI.\n").ok();
        rec_num += 1;
    }

    // Open-source opportunity
    let open_count = classifications
        .iter()
        .filter(|(_, c)| c.license == model_classifier::ModelLicense::OpenSource)
        .count();
    if total > 0 && (open_count as f64 / total as f64) < 0.1 {
        writeln!(
            md,
            "{}. **Open-Source Opportunity**: {:.1}% of sessions use open-source models.",
            rec_num,
            open_count as f64 / total as f64 * 100.0
        )
        .ok();
        writeln!(md, "   Consider local models (Ollama + DeepSeek/Llama) for non-sensitive code to reduce costs.\n").ok();
        rec_num += 1;
    }

    if rec_num == 1 {
        writeln!(
            md,
            "No specific recommendations at this time. Usage patterns look good!"
        )
        .ok();
    }
}

fn scan_prompts_for_secrets(receipts: &[&Receipt]) -> Vec<SecurityFinding> {
    let mut findings = Vec::new();
    for r in receipts {
        let result = redact::redact_with_report(&r.prompt_summary);
        for d in &result.detections {
            findings.push(SecurityFinding {
                session_id: r.session_id.chars().take(8).collect(),
                date: r.timestamp.format("%Y-%m-%d").to_string(),
                user: r.user.clone(),
                secret_type: d.secret_type.clone(),
                severity: d.severity.clone(),
            });
        }
    }
    findings
}
